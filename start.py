"""
Script de d√©marrage pour l'Agent Knowledge Interne
"""
import subprocess
import sys
import time
import requests
from pathlib import Path

def check_ollama_status():
    """V√©rifier si Ollama est disponible"""
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        return response.status_code == 200
    except:
        return False

def start_ollama():
    """D√©marrer Ollama avec Docker"""
    print("üê≥ D√©marrage d'Ollama...")
    
    try:
        # V√©rifier si Ollama est d√©j√† en cours d'ex√©cution
        if check_ollama_status():
            print("‚úÖ Ollama est d√©j√† en cours d'ex√©cution")
            return True
        
        # D√©marrer Ollama
        result = subprocess.run([
            "docker", "run", "-d", 
            "--name", "ollama-agentia",
            "-p", "11434:11434",
            "-v", "ollama_data:/root/.ollama",
            "ollama/ollama:latest"
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            print("‚úÖ Ollama d√©marr√© avec succ√®s")
            
            # Attendre que le service soit pr√™t
            print("‚è≥ Attente du d√©marrage d'Ollama...")
            for i in range(30):  # Attendre maximum 30 secondes
                if check_ollama_status():
                    print("‚úÖ Ollama est pr√™t")
                    return True
                time.sleep(1)
            
            print("‚ö†Ô∏è Ollama prend plus de temps que pr√©vu √† d√©marrer")
            return False
        else:
            print(f"‚ùå Erreur lors du d√©marrage d'Ollama: {result.stderr}")
            return False
            
    except FileNotFoundError:
        print("‚ùå Docker n'est pas install√© ou n'est pas dans le PATH")
        return False
    except Exception as e:
        print(f"‚ùå Erreur lors du d√©marrage d'Ollama: {e}")
        return False

def pull_llama_model():
    """T√©l√©charger le mod√®le Llama"""
    print("üì• T√©l√©chargement du mod√®le Llama...")
    
    try:
        result = subprocess.run([
            "docker", "exec", "ollama-agentia",
            "ollama", "pull", "llama3:8b"
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            print("‚úÖ Mod√®le Llama t√©l√©charg√©")
            return True
        else:
            print(f"‚ùå Erreur lors du t√©l√©chargement: {result.stderr}")
            return False
            
    except Exception as e:
        print(f"‚ùå Erreur lors du t√©l√©chargement du mod√®le: {e}")
        return False

def setup_environment():
    """Configurer l'environnement"""
    print("üîß Configuration de l'environnement...")
    
    # Cr√©er les r√©pertoires n√©cessaires
    directories = ['data', 'chroma_db', 'logs']
    for directory in directories:
        Path(directory).mkdir(exist_ok=True)
        print(f"‚úÖ R√©pertoire {directory} cr√©√©")
    
    # Copier le fichier de configuration
    config_file = Path('config.env')
    if not config_file.exists():
        print("‚ö†Ô∏è Fichier config.env non trouv√©")
        print("   Cr√©ez le fichier config.env √† partir de config.env.example")
        return False
    
    print("‚úÖ Configuration termin√©e")
    return True

def start_streamlit():
    """D√©marrer l'application Streamlit"""
    print("üöÄ D√©marrage de l'application Streamlit...")
    
    try:
        subprocess.run([
            sys.executable, "-m", "streamlit", "run", "app.py",
            "--server.port=8501",
            "--server.address=0.0.0.0"
        ])
    except KeyboardInterrupt:
        print("\nüëã Arr√™t de l'application")
    except Exception as e:
        print(f"‚ùå Erreur lors du d√©marrage de Streamlit: {e}")

def main():
    """Fonction principale"""
    print("ü§ñ Agent Knowledge Interne - Script de D√©marrage")
    print("=" * 50)
    
    # Configuration de l'environnement
    if not setup_environment():
        print("‚ùå √âchec de la configuration")
        return
    
    # D√©marrer Ollama
    if not start_ollama():
        print("‚ùå Impossible de d√©marrer Ollama")
        print("   Vous pouvez d√©marrer l'application sans Ollama pour tester l'interface")
        response = input("Continuer sans Ollama ? (y/N): ")
        if response.lower() != 'y':
            return
    
    # T√©l√©charger le mod√®le Llama
    if check_ollama_status():
        if not pull_llama_model():
            print("‚ö†Ô∏è Mod√®le Llama non t√©l√©charg√©")
            print("   Vous pouvez le t√©l√©charger manuellement plus tard")
    
    # D√©marrer l'application
    print("\nüåê D√©marrage de l'application web...")
    print("   L'application sera accessible sur: http://localhost:8501")
    print("   Appuyez sur Ctrl+C pour arr√™ter")
    
    start_streamlit()

if __name__ == "__main__":
    main()
